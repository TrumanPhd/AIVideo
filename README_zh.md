这个仓库包含了一套全自动的AI视频生产、以及自动在公众号等平台发布的脚本实现。
下面是在做这个项目时的一些思路：
总流程
大型语言模型（LLM）生成视频提示 -> 视频生成模型 -> 本地背景音乐匹配（基于文本提示词）-> 发布
macbook -> LLM服务器获取提示词 (TP) -> macbook -> 将 TP 发送给 T2V 模型 -> 下载视频到 macbook -> 本地音乐库搜索匹配音频 -> 合成对应视频 -> 视频本地存储并发布到多平台。
注册部署
Tiktok 抖音 (西瓜视频抖音系) 需要管理员权限审核。
Bilibili 需要认证。
Youtube 已经跑通。
快手
中文平台的视频题目要做汉化。
2.1 text2video 生成一些现实中没有的脑洞镜头。
效果验证
调用智谱 GLM API 生成语义提示词。
调用生成视频：
脑洞大开视频 结合一些网络热梗。
2.2 image2video
视频类型：（可以通过邮箱多注册几个账号试试）
擦边类：大尺度真实美女、动漫美女，微动作 - 跳舞。有的模型会拒绝生成。
打架、功夫。
TP -> 扩散模型 -> 视频。
历史进步类？
脑洞大开类？
真实的变成虚幻的场景虚构。
实施方案
要求： 编写 Python 脚本，添加中文注释，在 mac 环境中运行。从视频生成到发布的全流程自动化。文本提示调用语言模型 API，视频调用模型采用云端生成。
调用语言模型自动生成 text prompt： 要求大开脑洞、有天马行空的想象。要发布到短视频平台，必须能吸引订阅和点赞。视频平台的视频封面通常是视频的第一帧。
路径参数要求：
将生成的视频保存在 /Users/truman/AIGC/Video 文件夹下。
命名规则：以 V + 日期 + 代码命名（例：V20251230000001）。
视频自动发布平台：
Youtube @VideoAIGC 账号。
Tiktok @videoaigc 账号。
模型调用： Pika 系列模型。
视频内容的提示词生成： 通过智谱 GLM-4 生成。
背景音乐： 在将生成的视频下载之后自动添加背景音乐。
构建背景音乐库
5秒的背景音乐库： 按照情感分类。
10秒的库： 以后再做。
视频生成模型
基本都能直接 T2V，有些可以添加 Image 的提示来完善效果。
主力：
Pika 系列: 0.5秒。推荐。I2V、T2V、I+T2V。次便宜推荐，易于部署。
可灵: 1.6。推荐。提供 T2V、T+(1-4个)I2V 多种接口。只用5秒。最便宜。使用国内手机登录。API 访问贵。
备用：
Runway Gen-3: 质量最高（Gen-2 受到训练数据影响有西方偏见）。5人民币一个视频太贵，不推荐。
T2V: 腾讯混元 (Hunyuan): https://aivideo.hunyuan.tencent.com/。以横版为主，生成的竖版像两个横版的拼接。画质仍需提升，动作幅度有待考量。API: https://cloud.tencent.com/document/product/1729。5秒。没有 API 调用接口。
I2V、T2V (T2I2V): Stable Video Diffusion: 只有4秒。大尺度容易拒绝生成，不推荐。https://www.stablevideo.com/generate。
T2V: Meta MovieGen: 尚未对大众开放，以后试试。
T2V: Google Veo2: 尚未对大众开放，以后试试。
T2V: Sora V2: 20/200美元，与 GPT 捆绑销售。Tier 1。但效果不是最好，性价比不高。可以试试。
T2V: ModelScope Text to Video: 清晰度不行，太弱了，凑合用的水平，23年的老免费模型。
技术现状与注意：
有些比较偏的场景会出现不一致性。
用英文做提示词！
老模型做真实（real）风格的能力不行，尽量使用卡通（Cartoon）风格。
图片提示时，有些模型会因为擦边图片、大尺度而拒绝生成。
当有 5秒和 10秒可选时，都用 5秒。现在的模型生成的 10秒视频都太空洞。
